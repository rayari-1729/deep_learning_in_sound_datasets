{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h1MgwxiJTw5R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import librosa\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset\n",
        "!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz -O urban8k.tgz\n",
        "!tar -xzf urban8k.tgz\n",
        "!rm urban8k.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "segGeocAUL3N",
        "outputId": "23f70d0f-a6b6-46d9-b405-e6f3b357a413"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 14:56:34--  https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6023741708 (5.6G) [application/octet-stream]\n",
            "Saving to: ‘urban8k.tgz’\n",
            "\n",
            "urban8k.tgz         100%[===================>]   5.61G  2.69MB/s    in 32m 16s \n",
            "\n",
            "2023-04-21 15:28:51 (2.97 MB/s) - ‘urban8k.tgz’ saved [6023741708/6023741708]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Design Choices and Models\n",
        "\n",
        "After analysing the dataset I have made the following steps : \n",
        "\n",
        "  Train a Convolutional Neural Network and use either MFCCs, STFT or Mel-Spectogram as input. \n",
        "    \n",
        "  * As the audios duration range from 0 to 4s, I pad the spectogram generated, to make all the audios of equal length.\n",
        "  * Using MFCCs as features: \n",
        "     * It is usual to compute the first 13 MFCCs, their derivatives and second derivatives and use it as features.\n",
        "     * Or it is also usual to use 40 MFCCs as it is the Librosa default.\n",
        "  * Using the STFT as features:\n",
        "     * Contains less human processing than MFCCs and Mel-Spectogram, the CNN could learn other filters rather than the representations designed by humans.\n",
        "  * Using Mel-Spectogram as features: \n",
        "     * A transformation applied on the STFT that approximates how humans perceive the sound. Less human engineered than MFCCs but a bit more than STFT. \n",
        "     \n",
        "          \n"
      ],
      "metadata": {
        "id": "VOc1173xUgso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First choice would be using STFT and Mel-Spectogram as it looks that CNNs could take more advantage of the frequency-temporal structure but due to computational resources and limited time I will show the use MFCCs as features as they are much more memory efficient.**"
      ],
      "metadata": {
        "id": "NQPDjykeXUID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preprocessing and Splits"
      ],
      "metadata": {
        "id": "lSkgG0HjXsDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I load all the audio data using Librosa and the default sample rate of 22050Hz. This design decision is based on (Source and in further experiments different sample rates could be tried. \n",
        "\n",
        "       Humans can hear up to around 20000 Hz, it's possible to successfully analyze music and speech data at much lower rates without sacrificing much. \n",
        "       The highest pitches we usually care about detecting are around C9≈8372 Hz, well below the 11025 cutoff implied by fs=22050.\n",
        "       \n",
        "\n",
        "By default Librosa will load the audio in mono, giving us 1 channel       "
      ],
      "metadata": {
        "id": "g9qM_GE0XubK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FeatureExtractor class including librosa audio processing functions\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv_file = csv_file\n",
        "        self.max_audio_duration = 4\n",
        "        self.dataset_df = self._create_dataset(csv_file)\n",
        "    \n",
        "    @staticmethod\n",
        "    def _create_dataset(csv_file):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataset_path: path with the .wav files after unzipping\n",
        "        Returns: A pandas dataframe with the list of files and labels (`filenames`, `labels`)\n",
        "        \"\"\"\n",
        "        dataset_df = pd.read_csv(csv_file)\n",
        "        filepaths = []\n",
        "        for i, row in dataset_df.iterrows():\n",
        "            filepaths.append(os.path.join('UrbanSound8K/audio', 'fold'+str(row['fold']), row['slice_file_name']))\n",
        "        dataset_df['filepath'] = filepaths\n",
        "        return dataset_df\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_max_pad_length(max_audio_length, sample_rate=22050, n_fft=2048, hop_length=512):\n",
        "        dummy_file = np.random.random(max_audio_length*sample_rate)\n",
        "        stft = librosa.stft(dummy_file, n_fft=n_fft, hop_length=hop_length)\n",
        "        # Return an even number for CNN computation purposes\n",
        "        if stft.shape[1] % 2 != 0:\n",
        "            return stft.shape[1] + 1\n",
        "        return stft.shape[1]\n",
        "\n",
        "    def compute_save_features(self, \n",
        "                        mode='mfcc', \n",
        "                        sample_rate=22050,\n",
        "                        n_fft=2048,\n",
        "                        hop_length=512,\n",
        "                        n_mfcc=40,\n",
        "                        output_path='features',\n",
        "                        deltas=False\n",
        "                        ):\n",
        "        dataset_features = []\n",
        "        max_pad = self._compute_max_pad_length(self.max_audio_duration, \n",
        "                                               sample_rate=sample_rate, \n",
        "                                               n_fft=n_fft,\n",
        "                                               hop_length=hop_length)\n",
        "        print('Max Padding = ', max_pad)\n",
        "        \n",
        "        if not os.path.exists(output_path):\n",
        "            print('Creating output folder: ', output_path)\n",
        "            os.makedirs(output_path)\n",
        "        else:\n",
        "            print('Output folder already existed')\n",
        "            \n",
        "        print('Saving features in ', output_path)\n",
        "        i = 0\n",
        "        t = time.time()\n",
        "        \n",
        "        features_path = []\n",
        "        for filepath in self.dataset_df['filepath']:\n",
        "            if i % 100 == 0:\n",
        "                print('{} files processed in {}s'.format(i, time.time() - t))\n",
        "            audio_file, sample_rate = librosa.load(filepath, sr=sample_rate, res_type='kaiser_fast')\n",
        "            if mode == 'mfcc':\n",
        "                audio_features = self.compute_mfcc(audio_file, sample_rate, n_fft, hop_length, n_mfcc, deltas)  \n",
        "            elif mode == 'stft':\n",
        "                audio_features = self.compute_stft(audio_file, sample_rate, n_fft, hop_length)\n",
        "            elif mode == 'mel-spectogram':\n",
        "                audio_features = self.compute_mel_spectogram(audio_file, sample_rate, n_fft, hop_length)\n",
        "            \n",
        "            audio_features = np.pad(audio_features, \n",
        "                                    pad_width=((0, 0), (0, max_pad - audio_features.shape[1])))\n",
        "            \n",
        "            save_path = os.path.join(output_path, filepath.split('/')[-1].replace('wav', 'npy'))\n",
        "            self.save_features(audio_features, save_path)\n",
        "            features_path.append(save_path)\n",
        "            i+=1\n",
        "        self.dataset_df['features_path'] = features_path\n",
        "        return self.dataset_df\n",
        "    \n",
        "    @staticmethod\n",
        "\n",
        "    def save_features(audio_features, filepath):\n",
        "        np.save(filepath, audio_features)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_mel_spectogram(audio_file, sample_rate, n_fft, hop_length):\n",
        "        return librosa.feature.melspectrogram(audio_file,\n",
        "                                              sr=sample_rate, \n",
        "                                              n_fft=n_fft,\n",
        "                                              hop_length=hop_length)\n",
        "    @staticmethod\n",
        "    def compute_stft(audio_file, sample_rate, n_fft, hop_length):\n",
        "        return librosa.stft(audio_file, n_fft=n_fft, hop_length=hop_length)\n",
        "    \n",
        "    @staticmethod\n",
        "    def compute_mfcc(audio_file, sample_rate, n_fft, hop_length, n_mfcc, deltas=False):\n",
        "        mfccs = librosa.feature.mfcc(audio_file,\n",
        "                                    sr=sample_rate, \n",
        "                                    n_fft=n_fft,\n",
        "                                    n_mfcc=n_mfcc,\n",
        "                                    )\n",
        "        # Change mode from interpolation to nearest\n",
        "        if deltas:\n",
        "          delta_mfccs = librosa.feature.delta(mfccs, mode='nearest')\n",
        "          delta2_mfccs = librosa.feature.delta(mfccs, order=2, mode='nearest')\n",
        "          return np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
        "        return mfccs                "
      ],
      "metadata": {
        "id": "Clira5xBUhpk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and extract features\n",
        "fe = FeatureExtractor('UrbanSound8K/metadata/UrbanSound8K.csv')"
      ],
      "metadata": {
        "id": "mvzf-9PuYPhO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Access to disc and librosa loading of audio files is very slow on colab Notebook (30-40 min) we could load the pre-computed features instead.**"
      ],
      "metadata": {
        "id": "Z_3RFNP8YVa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip features\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BU2B5EcbfyGBIOkB5YC44hpzPpuqw43H' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BU2B5EcbfyGBIOkB5YC44hpzPpuqw43H\" -O features_mfcc.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q features_mfcc.zip\n",
        "!rm features_mfcc.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhiA04nFYkNi",
        "outputId": "50160c77-51f7-47d1-f16e-146af9e4bed7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 15:41:03--  https://docs.google.com/uc?export=download&confirm=t&id=1BU2B5EcbfyGBIOkB5YC44hpzPpuqw43H\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.121.102, 108.177.121.139, 108.177.121.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.121.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-00-1k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/cahusbfbunlpmtr2d5lb9g3oigs8pmih/1682091600000/12555612686504083087/*/1BU2B5EcbfyGBIOkB5YC44hpzPpuqw43H?e=download&uuid=4fe8bc91-d942-4279-9aac-27b2b10604d2 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-21 15:41:03--  https://doc-00-1k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/cahusbfbunlpmtr2d5lb9g3oigs8pmih/1682091600000/12555612686504083087/*/1BU2B5EcbfyGBIOkB5YC44hpzPpuqw43H?e=download&uuid=4fe8bc91-d942-4279-9aac-27b2b10604d2\n",
            "Resolving doc-00-1k-docs.googleusercontent.com (doc-00-1k-docs.googleusercontent.com)... 74.125.201.132, 2607:f8b0:4001:c01::84\n",
            "Connecting to doc-00-1k-docs.googleusercontent.com (doc-00-1k-docs.googleusercontent.com)|74.125.201.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203626094 (194M) [application/zip]\n",
            "Saving to: ‘features_mfcc.zip’\n",
            "\n",
            "features_mfcc.zip   100%[===================>] 194.19M  84.9MB/s    in 2.3s    \n",
            "\n",
            "2023-04-21 15:41:06 (84.9 MB/s) - ‘features_mfcc.zip’ saved [203626094/203626094]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset.json file\n",
        "!wget --no-check-certificate \"https://docs.google.com/uc?export=download&id=1pzSvGYaBXghLQFTZxlSex-Ts3T4B0X4C\" -O dataset.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC8OMFWzYkKr",
        "outputId": "bd14e862-7ce7-4d60-c156-25e7ae0f6855"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 15:41:25--  https://docs.google.com/uc?export=download&id=1pzSvGYaBXghLQFTZxlSex-Ts3T4B0X4C\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.121.102, 108.177.121.139, 108.177.121.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.121.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-1k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kqv7fapgqqugp52da4cgjq3tuqqmqs22/1682091675000/12555612686504083087/*/1pzSvGYaBXghLQFTZxlSex-Ts3T4B0X4C?e=download&uuid=5f2682f5-1e83-4ce5-8aac-52ed35473436 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-04-21 15:41:28--  https://doc-0s-1k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kqv7fapgqqugp52da4cgjq3tuqqmqs22/1682091675000/12555612686504083087/*/1pzSvGYaBXghLQFTZxlSex-Ts3T4B0X4C?e=download&uuid=5f2682f5-1e83-4ce5-8aac-52ed35473436\n",
            "Resolving doc-0s-1k-docs.googleusercontent.com (doc-0s-1k-docs.googleusercontent.com)... 74.125.201.132, 2607:f8b0:4001:c01::84\n",
            "Connecting to doc-0s-1k-docs.googleusercontent.com (doc-0s-1k-docs.googleusercontent.com)|74.125.201.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3014027 (2.9M) [application/json]\n",
            "Saving to: ‘dataset.json’\n",
            "\n",
            "dataset.json        100%[===================>]   2.87M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-21 15:41:28 (138 MB/s) - ‘dataset.json’ saved [3014027/3014027]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = pd.read_json('dataset.json')"
      ],
      "metadata": {
        "id": "vQ5rYtALYkFr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of this experiment we will load all the data in memory and process it in minibatches. If we had computational resources and more time we could create Dataloader objects that would allow to perform many other operations as Data Augmentation and iterate faster."
      ],
      "metadata": {
        "id": "4fX-pS6oYqry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df['features'] = [np.asarray(np.load(feature_path)) for feature_path in dataset_df['features_path']]"
      ],
      "metadata": {
        "id": "Ybou7ApuYkCz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "dataset_df['labels_categorical'] = [to_categorical(label, 10) for label in dataset_df['classID']]"
      ],
      "metadata": {
        "id": "OaFPhbPSYxEa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "7NhUzrQGYzjS",
        "outputId": "ac0866f2-6fb6-4b84-ba65-f18f076b4528"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class                                     filepath  \\\n",
              "0          dog_bark    UrbanSound8K/audio/fold5/100032-3-0-0.wav   \n",
              "1  children_playing  UrbanSound8K/audio/fold5/100263-2-0-117.wav   \n",
              "2  children_playing  UrbanSound8K/audio/fold5/100263-2-0-121.wav   \n",
              "3  children_playing  UrbanSound8K/audio/fold5/100263-2-0-126.wav   \n",
              "4  children_playing  UrbanSound8K/audio/fold5/100263-2-0-137.wav   \n",
              "\n",
              "                      features_path  \\\n",
              "0    features_mfcc/100032-3-0-0.npy   \n",
              "1  features_mfcc/100263-2-0-117.npy   \n",
              "2  features_mfcc/100263-2-0-121.npy   \n",
              "3  features_mfcc/100263-2-0-126.npy   \n",
              "4  features_mfcc/100263-2-0-137.npy   \n",
              "\n",
              "                                            features  \\\n",
              "0  [[[-306.77255], [-177.59209], [-99.13616], [-6...   \n",
              "1  [[[-457.69534], [-451.0248], [-450.68613], [-4...   \n",
              "2  [[[-468.0367], [-467.42264], [-481.04654], [-4...   \n",
              "3  [[[-422.42215], [-411.9085], [-409.46243], [-4...   \n",
              "4  [[[-438.10162], [-434.47787], [-443.3284], [-4...   \n",
              "\n",
              "                                  labels_categorical  \n",
              "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5d76aff-836d-4019-b1da-fe545ff6215d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "      <th>filepath</th>\n",
              "      <th>features_path</th>\n",
              "      <th>features</th>\n",
              "      <th>labels_categorical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "      <td>UrbanSound8K/audio/fold5/100032-3-0-0.wav</td>\n",
              "      <td>features_mfcc/100032-3-0-0.npy</td>\n",
              "      <td>[[[-306.77255], [-177.59209], [-99.13616], [-6...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "      <td>UrbanSound8K/audio/fold5/100263-2-0-117.wav</td>\n",
              "      <td>features_mfcc/100263-2-0-117.npy</td>\n",
              "      <td>[[[-457.69534], [-451.0248], [-450.68613], [-4...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "      <td>UrbanSound8K/audio/fold5/100263-2-0-121.wav</td>\n",
              "      <td>features_mfcc/100263-2-0-121.npy</td>\n",
              "      <td>[[[-468.0367], [-467.42264], [-481.04654], [-4...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "      <td>UrbanSound8K/audio/fold5/100263-2-0-126.wav</td>\n",
              "      <td>features_mfcc/100263-2-0-126.npy</td>\n",
              "      <td>[[[-422.42215], [-411.9085], [-409.46243], [-4...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "      <td>UrbanSound8K/audio/fold5/100263-2-0-137.wav</td>\n",
              "      <td>features_mfcc/100263-2-0-137.npy</td>\n",
              "      <td>[[[-438.10162], [-434.47787], [-443.3284], [-4...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5d76aff-836d-4019-b1da-fe545ff6215d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5d76aff-836d-4019-b1da-fe545ff6215d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5d76aff-836d-4019-b1da-fe545ff6215d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to create splits for the train, validation and test sets of our dataset. "
      ],
      "metadata": {
        "id": "fWzDh5z0Y97q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset \n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Add one dimension for the channel\n",
        "X = np.array(dataset_df['features'].tolist())\n",
        "y = np.array(dataset_df['labels_categorical'].tolist())\n",
        "\n",
        "# As there is unbalance for some classes I am going to stratify it so we have the same proportion in train/test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.30, \n",
        "                                                    random_state=1, \n",
        "                                                    stratify=y)\n",
        "# Create validation and test\n",
        "X_test, X_val, Y_test, Y_val = train_test_split(X_test, \n",
        "                                                Y_test, \n",
        "                                                test_size=0.5, \n",
        "                                                random_state=1, \n",
        "                                                stratify=Y_test)\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzrYg45BY-w6",
        "outputId": "2ade44b4-cc82-47b0-8df6-4cc2d13571e3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6112, 39, 174, 1) (1310, 39, 174, 1) (1310, 39, 174, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Model"
      ],
      "metadata": {
        "id": "_ion8kLTZEmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Design"
      ],
      "metadata": {
        "id": "OpuWaGHbZGls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a Fully Convolutional Network Model using Keras running over Tensorflow with a few layers."
      ],
      "metadata": {
        "id": "ka67fK26ZKKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "GCJ1jxTUZFMN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our images are rectangular in shape (y axis is MFCC, x axis is time), instead of using square filters (as usual) we are going to make them rectangular so they can learn better the correlation of the MFCCs with the temporal dimension."
      ],
      "metadata": {
        "id": "SPsShIbJZUSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FCN Model\n",
        "def create_model(num_classes=10, input_shape=None, dropout_ratio=None):\n",
        "    model = Sequential()\n",
        "    if input_shape is None:\n",
        "        model.add(Input(shape=(None, None, 1)))\n",
        "    else:\n",
        "        model.add(Input(shape=input_shape))\n",
        "    model.add(Conv2D(filters=16, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 3)))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(2, 4), activation='relu'))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    if dropout_ratio is not None:\n",
        "        model.add(Dropout(dropout_ratio))\n",
        "    # Add dense linear layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "     "
      ],
      "metadata": {
        "id": "AukL8v25ZOpK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is a multi classification problem we will use the Categorical Cross Entropy loss. As optimizer we will use the Keras implementation of Adam with the default hyperparameters values."
      ],
      "metadata": {
        "id": "kVTjtaUrZYh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create and compile the model\n",
        "fcn_model = create_model(input_shape=X_train.shape[1:])\n",
        "fcn_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "fcn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaWVAmbbZW6L",
        "outputId": "f02c4084-6fc9-4318-e1c2-56500466f7f5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 38, 171, 16)       144       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 19, 57, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 18, 54, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 9, 27, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 24, 64)         16448     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 12, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 9, 128)         65664     \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 128)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,674\n",
            "Trainable params: 87,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training and evaluation"
      ],
      "metadata": {
        "id": "WJRGFIK3Zbyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "fC5nsptXZcq9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir saved_models"
      ],
      "metadata": {
        "id": "8bZ2ssIQZgSS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, Y_train, X_val, Y_val, epochs, batch_size, callbacks):\n",
        "    model.fit(X_train, \n",
        "              Y_train, \n",
        "              batch_size=batch_size, \n",
        "              epochs=epochs, \n",
        "              validation_data=(X_val, Y_val), \n",
        "              callbacks=callbacks, verbose=1)\n",
        "    return model"
      ],
      "metadata": {
        "id": "mlgGxNXYZjKi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a checkpoint for early stopping, so we will select the model that performs better on the validation set."
      ],
      "metadata": {
        "id": "mxc8YvPiZmL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a function to train the model will allow us to perform hyperparameter tuning faster."
      ],
      "metadata": {
        "id": "qV-22M2tZn-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(filepath='saved_models/best_fcn.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "callbacks = [checkpointer]\n",
        "\n",
        "# Hyper-parameters\n",
        "epochs = 200\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "1nTLwYCdZog9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = train_model(model=fcn_model,\n",
        "                    X_train=X_train,\n",
        "                    X_val=X_val,\n",
        "                    Y_train=Y_train,\n",
        "                    Y_val=Y_val,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=callbacks)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLxMqddrZrqX",
        "outputId": "17d8400e-8e23-40c4-a885-a3736d712b35"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0849 - accuracy: 0.9733\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86183, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 0.0849 - accuracy: 0.9735 - val_loss: 0.4863 - val_accuracy: 0.8618\n",
            "Epoch 2/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0917 - accuracy: 0.9666\n",
            "Epoch 2: val_accuracy improved from 0.86183 to 0.88397, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0889 - accuracy: 0.9683 - val_loss: 0.4765 - val_accuracy: 0.8840\n",
            "Epoch 3/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9719\n",
            "Epoch 3: val_accuracy did not improve from 0.88397\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0823 - accuracy: 0.9719 - val_loss: 0.5148 - val_accuracy: 0.8740\n",
            "Epoch 4/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9704\n",
            "Epoch 4: val_accuracy did not improve from 0.88397\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0865 - accuracy: 0.9704 - val_loss: 0.5576 - val_accuracy: 0.8756\n",
            "Epoch 5/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9619\n",
            "Epoch 5: val_accuracy did not improve from 0.88397\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.1016 - accuracy: 0.9619 - val_loss: 0.5282 - val_accuracy: 0.8740\n",
            "Epoch 6/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0792 - accuracy: 0.9727\n",
            "Epoch 6: val_accuracy improved from 0.88397 to 0.88702, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0780 - accuracy: 0.9728 - val_loss: 0.4627 - val_accuracy: 0.8870\n",
            "Epoch 7/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0587 - accuracy: 0.9817\n",
            "Epoch 7: val_accuracy improved from 0.88702 to 0.89466, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0577 - accuracy: 0.9822 - val_loss: 0.4262 - val_accuracy: 0.8947\n",
            "Epoch 8/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0511 - accuracy: 0.9864\n",
            "Epoch 8: val_accuracy improved from 0.89466 to 0.89542, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0513 - accuracy: 0.9861 - val_loss: 0.4589 - val_accuracy: 0.8954\n",
            "Epoch 9/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9890\n",
            "Epoch 9: val_accuracy improved from 0.89542 to 0.89771, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0397 - accuracy: 0.9890 - val_loss: 0.4470 - val_accuracy: 0.8977\n",
            "Epoch 10/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0393 - accuracy: 0.9904\n",
            "Epoch 10: val_accuracy improved from 0.89771 to 0.90229, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0394 - accuracy: 0.9900 - val_loss: 0.4222 - val_accuracy: 0.9023\n",
            "Epoch 11/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9933\n",
            "Epoch 11: val_accuracy improved from 0.90229 to 0.90305, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0325 - accuracy: 0.9933 - val_loss: 0.4184 - val_accuracy: 0.9031\n",
            "Epoch 12/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9907\n",
            "Epoch 12: val_accuracy did not improve from 0.90305\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.4494 - val_accuracy: 0.8962\n",
            "Epoch 13/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0339 - accuracy: 0.9909\n",
            "Epoch 13: val_accuracy did not improve from 0.90305\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.4667 - val_accuracy: 0.9008\n",
            "Epoch 14/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0315 - accuracy: 0.9929\n",
            "Epoch 14: val_accuracy did not improve from 0.90305\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0327 - accuracy: 0.9926 - val_loss: 0.4711 - val_accuracy: 0.8969\n",
            "Epoch 15/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9885\n",
            "Epoch 15: val_accuracy improved from 0.90305 to 0.90687, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0394 - accuracy: 0.9885 - val_loss: 0.4323 - val_accuracy: 0.9069\n",
            "Epoch 16/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0438 - accuracy: 0.9873\n",
            "Epoch 16: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.0432 - accuracy: 0.9874 - val_loss: 0.4983 - val_accuracy: 0.8878\n",
            "Epoch 17/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0883 - accuracy: 0.9702\n",
            "Epoch 17: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.0916 - accuracy: 0.9689 - val_loss: 0.6229 - val_accuracy: 0.8611\n",
            "Epoch 18/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1519 - accuracy: 0.9475\n",
            "Epoch 18: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.1515 - accuracy: 0.9476 - val_loss: 0.6068 - val_accuracy: 0.8740\n",
            "Epoch 19/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0888 - accuracy: 0.9689\n",
            "Epoch 19: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0859 - accuracy: 0.9704 - val_loss: 0.4785 - val_accuracy: 0.8885\n",
            "Epoch 20/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0465 - accuracy: 0.9867\n",
            "Epoch 20: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0459 - accuracy: 0.9871 - val_loss: 0.4401 - val_accuracy: 0.8954\n",
            "Epoch 21/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9935\n",
            "Epoch 21: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0274 - accuracy: 0.9935 - val_loss: 0.4175 - val_accuracy: 0.9038\n",
            "Epoch 22/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9956\n",
            "Epoch 22: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 0.4220 - val_accuracy: 0.9061\n",
            "Epoch 23/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0174 - accuracy: 0.9968\n",
            "Epoch 23: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0176 - accuracy: 0.9967 - val_loss: 0.4388 - val_accuracy: 0.9031\n",
            "Epoch 24/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9975\n",
            "Epoch 24: val_accuracy did not improve from 0.90687\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0168 - accuracy: 0.9975 - val_loss: 0.4394 - val_accuracy: 0.9061\n",
            "Epoch 25/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0178 - accuracy: 0.9970\n",
            "Epoch 25: val_accuracy improved from 0.90687 to 0.90916, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.4456 - val_accuracy: 0.9092\n",
            "Epoch 26/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9975\n",
            "Epoch 26: val_accuracy did not improve from 0.90916\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.4441 - val_accuracy: 0.9053\n",
            "Epoch 27/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0158 - accuracy: 0.9973\n",
            "Epoch 27: val_accuracy did not improve from 0.90916\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.4470 - val_accuracy: 0.9092\n",
            "Epoch 28/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9984\n",
            "Epoch 28: val_accuracy improved from 0.90916 to 0.91145, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9984 - val_loss: 0.4634 - val_accuracy: 0.9115\n",
            "Epoch 29/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0124 - accuracy: 0.9986\n",
            "Epoch 29: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0123 - accuracy: 0.9985 - val_loss: 0.4530 - val_accuracy: 0.9076\n",
            "Epoch 30/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9987\n",
            "Epoch 30: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 0.4594 - val_accuracy: 0.9115\n",
            "Epoch 31/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0093 - accuracy: 0.9991\n",
            "Epoch 31: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.4675 - val_accuracy: 0.9107\n",
            "Epoch 32/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9972\n",
            "Epoch 32: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.4571 - val_accuracy: 0.9099\n",
            "Epoch 33/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0095 - accuracy: 0.9988\n",
            "Epoch 33: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.4829 - val_accuracy: 0.9092\n",
            "Epoch 34/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0125 - accuracy: 0.9986\n",
            "Epoch 34: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0130 - accuracy: 0.9982 - val_loss: 0.5322 - val_accuracy: 0.9038\n",
            "Epoch 35/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2735 - accuracy: 0.9368\n",
            "Epoch 35: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.2766 - accuracy: 0.9360 - val_loss: 1.0720 - val_accuracy: 0.7817\n",
            "Epoch 36/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.3332 - accuracy: 0.8956\n",
            "Epoch 36: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.3231 - accuracy: 0.8984 - val_loss: 0.4577 - val_accuracy: 0.8580\n",
            "Epoch 37/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1388 - accuracy: 0.9478\n",
            "Epoch 37: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1347 - accuracy: 0.9501 - val_loss: 0.4263 - val_accuracy: 0.8931\n",
            "Epoch 38/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0494 - accuracy: 0.9885\n",
            "Epoch 38: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0475 - accuracy: 0.9889 - val_loss: 0.4215 - val_accuracy: 0.9000\n",
            "Epoch 39/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0246 - accuracy: 0.9956\n",
            "Epoch 39: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 0.4093 - val_accuracy: 0.9099\n",
            "Epoch 40/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0183 - accuracy: 0.9977\n",
            "Epoch 40: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.4283 - val_accuracy: 0.9069\n",
            "Epoch 41/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9975\n",
            "Epoch 41: val_accuracy did not improve from 0.91145\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.4233 - val_accuracy: 0.9084\n",
            "Epoch 42/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9987\n",
            "Epoch 42: val_accuracy improved from 0.91145 to 0.91374, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.0129 - accuracy: 0.9987 - val_loss: 0.4333 - val_accuracy: 0.9137\n",
            "Epoch 43/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9979\n",
            "Epoch 43: val_accuracy did not improve from 0.91374\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.4507 - val_accuracy: 0.9061\n",
            "Epoch 44/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0129 - accuracy: 0.9986\n",
            "Epoch 44: val_accuracy did not improve from 0.91374\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0127 - accuracy: 0.9987 - val_loss: 0.4556 - val_accuracy: 0.9092\n",
            "Epoch 45/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9980\n",
            "Epoch 45: val_accuracy did not improve from 0.91374\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: 0.4608 - val_accuracy: 0.9130\n",
            "Epoch 46/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0111 - accuracy: 0.9990\n",
            "Epoch 46: val_accuracy did not improve from 0.91374\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 0.9990 - val_loss: 0.4734 - val_accuracy: 0.9084\n",
            "Epoch 47/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0113 - accuracy: 0.9980\n",
            "Epoch 47: val_accuracy did not improve from 0.91374\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.4679 - val_accuracy: 0.9122\n",
            "Epoch 48/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9985\n",
            "Epoch 48: val_accuracy did not improve from 0.91374\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0096 - accuracy: 0.9985 - val_loss: 0.4661 - val_accuracy: 0.9130\n",
            "Epoch 49/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0073 - accuracy: 0.9991\n",
            "Epoch 49: val_accuracy improved from 0.91374 to 0.91603, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.4602 - val_accuracy: 0.9160\n",
            "Epoch 50/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0096 - accuracy: 0.9982\n",
            "Epoch 50: val_accuracy did not improve from 0.91603\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.4969 - val_accuracy: 0.9061\n",
            "Epoch 51/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0178 - accuracy: 0.9964\n",
            "Epoch 51: val_accuracy did not improve from 0.91603\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0170 - accuracy: 0.9967 - val_loss: 0.4944 - val_accuracy: 0.9061\n",
            "Epoch 52/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0155 - accuracy: 0.9966\n",
            "Epoch 52: val_accuracy improved from 0.91603 to 0.91679, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.4774 - val_accuracy: 0.9168\n",
            "Epoch 53/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0100 - accuracy: 0.9988\n",
            "Epoch 53: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.5090 - val_accuracy: 0.9038\n",
            "Epoch 54/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0117 - accuracy: 0.9980\n",
            "Epoch 54: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.4874 - val_accuracy: 0.9130\n",
            "Epoch 55/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0066 - accuracy: 0.9995\n",
            "Epoch 55: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.4889 - val_accuracy: 0.9130\n",
            "Epoch 56/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0062 - accuracy: 0.9993\n",
            "Epoch 56: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.4981 - val_accuracy: 0.9168\n",
            "Epoch 57/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993\n",
            "Epoch 57: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.4860 - val_accuracy: 0.9092\n",
            "Epoch 58/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993\n",
            "Epoch 58: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.5031 - val_accuracy: 0.9153\n",
            "Epoch 59/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0059 - accuracy: 0.9989\n",
            "Epoch 59: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.5002 - val_accuracy: 0.9130\n",
            "Epoch 60/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0048 - accuracy: 0.9991\n",
            "Epoch 60: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.5067 - val_accuracy: 0.9115\n",
            "Epoch 61/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9985\n",
            "Epoch 61: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.5149 - val_accuracy: 0.9092\n",
            "Epoch 62/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0096 - accuracy: 0.9976\n",
            "Epoch 62: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.5210 - val_accuracy: 0.9099\n",
            "Epoch 63/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0072 - accuracy: 0.9985\n",
            "Epoch 63: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.5004 - val_accuracy: 0.9130\n",
            "Epoch 64/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9993\n",
            "Epoch 64: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.5056 - val_accuracy: 0.9069\n",
            "Epoch 65/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0054 - accuracy: 0.9992\n",
            "Epoch 65: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.5136 - val_accuracy: 0.9107\n",
            "Epoch 66/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0067 - accuracy: 0.9988\n",
            "Epoch 66: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.5202 - val_accuracy: 0.9153\n",
            "Epoch 67/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0060 - accuracy: 0.9989\n",
            "Epoch 67: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.5233 - val_accuracy: 0.9115\n",
            "Epoch 68/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0073 - accuracy: 0.9982\n",
            "Epoch 68: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5262 - val_accuracy: 0.9092\n",
            "Epoch 69/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0188 - accuracy: 0.9950\n",
            "Epoch 69: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.5655 - val_accuracy: 0.9031\n",
            "Epoch 70/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 0.9802\n",
            "Epoch 70: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0535 - accuracy: 0.9802 - val_loss: 0.8387 - val_accuracy: 0.8611\n",
            "Epoch 71/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1502 - accuracy: 0.9538\n",
            "Epoch 71: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1489 - accuracy: 0.9534 - val_loss: 0.6973 - val_accuracy: 0.8634\n",
            "Epoch 72/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9557\n",
            "Epoch 72: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1504 - accuracy: 0.9557 - val_loss: 0.5566 - val_accuracy: 0.8824\n",
            "Epoch 73/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9741\n",
            "Epoch 73: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0835 - accuracy: 0.9741 - val_loss: 0.4951 - val_accuracy: 0.9038\n",
            "Epoch 74/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0499 - accuracy: 0.9838\n",
            "Epoch 74: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0494 - accuracy: 0.9843 - val_loss: 0.4756 - val_accuracy: 0.9076\n",
            "Epoch 75/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0281 - accuracy: 0.9927\n",
            "Epoch 75: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.4844 - val_accuracy: 0.9069\n",
            "Epoch 76/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9964\n",
            "Epoch 76: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.4904 - val_accuracy: 0.9076\n",
            "Epoch 77/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0129 - accuracy: 0.9980\n",
            "Epoch 77: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.4776 - val_accuracy: 0.9084\n",
            "Epoch 78/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0110 - accuracy: 0.9984\n",
            "Epoch 78: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0107 - accuracy: 0.9985 - val_loss: 0.4827 - val_accuracy: 0.9153\n",
            "Epoch 79/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0067 - accuracy: 0.9988\n",
            "Epoch 79: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.4737 - val_accuracy: 0.9153\n",
            "Epoch 80/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0066 - accuracy: 0.9989\n",
            "Epoch 80: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.4699 - val_accuracy: 0.9168\n",
            "Epoch 81/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9990\n",
            "Epoch 81: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.5059 - val_accuracy: 0.9115\n",
            "Epoch 82/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0042 - accuracy: 0.9992\n",
            "Epoch 82: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.4984 - val_accuracy: 0.9130\n",
            "Epoch 83/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0046 - accuracy: 0.9991\n",
            "Epoch 83: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.4980 - val_accuracy: 0.9099\n",
            "Epoch 84/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0073 - accuracy: 0.9981\n",
            "Epoch 84: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.5156 - val_accuracy: 0.9107\n",
            "Epoch 85/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9992\n",
            "Epoch 85: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5172 - val_accuracy: 0.9115\n",
            "Epoch 86/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 0.9993\n",
            "Epoch 86: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.5204 - val_accuracy: 0.9145\n",
            "Epoch 87/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993\n",
            "Epoch 87: val_accuracy improved from 0.91679 to 0.92137, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.5109 - val_accuracy: 0.9214\n",
            "Epoch 88/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0051 - accuracy: 0.9993\n",
            "Epoch 88: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.5210 - val_accuracy: 0.9038\n",
            "Epoch 89/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9987\n",
            "Epoch 89: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.5425 - val_accuracy: 0.9092\n",
            "Epoch 90/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0063 - accuracy: 0.9991\n",
            "Epoch 90: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.5162 - val_accuracy: 0.9183\n",
            "Epoch 91/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988\n",
            "Epoch 91: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.5260 - val_accuracy: 0.9176\n",
            "Epoch 92/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9993\n",
            "Epoch 92: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.5459 - val_accuracy: 0.9137\n",
            "Epoch 93/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9990\n",
            "Epoch 93: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.5433 - val_accuracy: 0.9107\n",
            "Epoch 94/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993\n",
            "Epoch 94: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.5345 - val_accuracy: 0.9137\n",
            "Epoch 95/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 95: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.5273 - val_accuracy: 0.9122\n",
            "Epoch 96/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 96: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.5195 - val_accuracy: 0.9153\n",
            "Epoch 97/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 97: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.5282 - val_accuracy: 0.9160\n",
            "Epoch 98/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
            "Epoch 98: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.5650 - val_accuracy: 0.9107\n",
            "Epoch 99/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0728 - accuracy: 0.9783\n",
            "Epoch 99: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0735 - accuracy: 0.9782 - val_loss: 0.7193 - val_accuracy: 0.8779\n",
            "Epoch 100/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9512\n",
            "Epoch 100: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.1571 - accuracy: 0.9512 - val_loss: 0.6025 - val_accuracy: 0.8779\n",
            "Epoch 101/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.9647\n",
            "Epoch 101: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.1067 - accuracy: 0.9647 - val_loss: 0.5401 - val_accuracy: 0.8885\n",
            "Epoch 102/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9813\n",
            "Epoch 102: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0584 - accuracy: 0.9813 - val_loss: 0.4573 - val_accuracy: 0.9076\n",
            "Epoch 103/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0471 - accuracy: 0.9840\n",
            "Epoch 103: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0466 - accuracy: 0.9843 - val_loss: 0.4923 - val_accuracy: 0.9061\n",
            "Epoch 104/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9923\n",
            "Epoch 104: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.4905 - val_accuracy: 0.9153\n",
            "Epoch 105/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9972\n",
            "Epoch 105: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.5291 - val_accuracy: 0.9069\n",
            "Epoch 106/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0084 - accuracy: 0.9984\n",
            "Epoch 106: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.4990 - val_accuracy: 0.9176\n",
            "Epoch 107/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995\n",
            "Epoch 107: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.5007 - val_accuracy: 0.9153\n",
            "Epoch 108/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0055 - accuracy: 0.9991\n",
            "Epoch 108: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.5065 - val_accuracy: 0.9115\n",
            "Epoch 109/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9990\n",
            "Epoch 109: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.4862 - val_accuracy: 0.9153\n",
            "Epoch 110/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993\n",
            "Epoch 110: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.5055 - val_accuracy: 0.9198\n",
            "Epoch 111/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0039 - accuracy: 0.9992\n",
            "Epoch 111: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.4952 - val_accuracy: 0.9206\n",
            "Epoch 112/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995\n",
            "Epoch 112: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.4998 - val_accuracy: 0.9137\n",
            "Epoch 113/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0056 - accuracy: 0.9988\n",
            "Epoch 113: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5233 - val_accuracy: 0.9145\n",
            "Epoch 114/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993\n",
            "Epoch 114: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.5023 - val_accuracy: 0.9130\n",
            "Epoch 115/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0047 - accuracy: 0.9989\n",
            "Epoch 115: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.5331 - val_accuracy: 0.9153\n",
            "Epoch 116/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0046 - accuracy: 0.9989\n",
            "Epoch 116: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.5086 - val_accuracy: 0.9160\n",
            "Epoch 117/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
            "Epoch 117: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.5081 - val_accuracy: 0.9176\n",
            "Epoch 118/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0055 - accuracy: 0.9989\n",
            "Epoch 118: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.5147 - val_accuracy: 0.9168\n",
            "Epoch 119/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 119: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.5036 - val_accuracy: 0.9176\n",
            "Epoch 120/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\n",
            "Epoch 120: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.5150 - val_accuracy: 0.9153\n",
            "Epoch 121/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995\n",
            "Epoch 121: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.5089 - val_accuracy: 0.9153\n",
            "Epoch 122/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 122: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.5196 - val_accuracy: 0.9176\n",
            "Epoch 123/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
            "Epoch 123: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.5268 - val_accuracy: 0.9137\n",
            "Epoch 124/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0037 - accuracy: 0.9992\n",
            "Epoch 124: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.5408 - val_accuracy: 0.9153\n",
            "Epoch 125/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 125: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.5446 - val_accuracy: 0.9183\n",
            "Epoch 126/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 0.9989\n",
            "Epoch 126: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.5488 - val_accuracy: 0.9160\n",
            "Epoch 127/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0110 - accuracy: 0.9977\n",
            "Epoch 127: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.5869 - val_accuracy: 0.9008\n",
            "Epoch 128/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9889\n",
            "Epoch 128: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0406 - accuracy: 0.9889 - val_loss: 0.6555 - val_accuracy: 0.9000\n",
            "Epoch 129/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0577 - accuracy: 0.9810\n",
            "Epoch 129: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: 0.6762 - val_accuracy: 0.8916\n",
            "Epoch 130/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0597 - accuracy: 0.9780\n",
            "Epoch 130: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0629 - accuracy: 0.9779 - val_loss: 0.6747 - val_accuracy: 0.8786\n",
            "Epoch 131/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9733\n",
            "Epoch 131: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0867 - accuracy: 0.9733 - val_loss: 0.6516 - val_accuracy: 0.8794\n",
            "Epoch 132/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9781\n",
            "Epoch 132: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0619 - accuracy: 0.9781 - val_loss: 0.5888 - val_accuracy: 0.8840\n",
            "Epoch 133/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9741\n",
            "Epoch 133: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0725 - accuracy: 0.9741 - val_loss: 0.5409 - val_accuracy: 0.8908\n",
            "Epoch 134/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9756\n",
            "Epoch 134: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 0.6461 - val_accuracy: 0.8786\n",
            "Epoch 135/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9872\n",
            "Epoch 135: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.5189 - val_accuracy: 0.9038\n",
            "Epoch 136/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0211 - accuracy: 0.9931\n",
            "Epoch 136: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.5223 - val_accuracy: 0.9038\n",
            "Epoch 137/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0126 - accuracy: 0.9973\n",
            "Epoch 137: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.4690 - val_accuracy: 0.9168\n",
            "Epoch 138/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
            "Epoch 138: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.4637 - val_accuracy: 0.9137\n",
            "Epoch 139/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993\n",
            "Epoch 139: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.4950 - val_accuracy: 0.9191\n",
            "Epoch 140/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0073 - accuracy: 0.9991\n",
            "Epoch 140: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.4711 - val_accuracy: 0.9168\n",
            "Epoch 141/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995\n",
            "Epoch 141: val_accuracy improved from 0.92137 to 0.92290, saving model to saved_models/best_fcn.hdf5\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.4803 - val_accuracy: 0.9229\n",
            "Epoch 142/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\n",
            "Epoch 142: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.4929 - val_accuracy: 0.9191\n",
            "Epoch 143/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993\n",
            "Epoch 143: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.5094 - val_accuracy: 0.9198\n",
            "Epoch 144/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988\n",
            "Epoch 144: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5012 - val_accuracy: 0.9160\n",
            "Epoch 145/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0031 - accuracy: 0.9993\n",
            "Epoch 145: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.5158 - val_accuracy: 0.9183\n",
            "Epoch 146/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 146: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.4984 - val_accuracy: 0.9183\n",
            "Epoch 147/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
            "Epoch 147: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.4925 - val_accuracy: 0.9183\n",
            "Epoch 148/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0032 - accuracy: 0.9992\n",
            "Epoch 148: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.5096 - val_accuracy: 0.9206\n",
            "Epoch 149/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
            "Epoch 149: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4998 - val_accuracy: 0.9198\n",
            "Epoch 150/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 150: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.5030 - val_accuracy: 0.9214\n",
            "Epoch 151/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
            "Epoch 151: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.5617 - val_accuracy: 0.9130\n",
            "Epoch 152/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 0.9988\n",
            "Epoch 152: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.5213 - val_accuracy: 0.9160\n",
            "Epoch 153/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
            "Epoch 153: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.5034 - val_accuracy: 0.9183\n",
            "Epoch 154/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
            "Epoch 154: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.5072 - val_accuracy: 0.9160\n",
            "Epoch 155/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993\n",
            "Epoch 155: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.5232 - val_accuracy: 0.9206\n",
            "Epoch 156/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993\n",
            "Epoch 156: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.5476 - val_accuracy: 0.9206\n",
            "Epoch 157/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
            "Epoch 157: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.5232 - val_accuracy: 0.9168\n",
            "Epoch 158/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993\n",
            "Epoch 158: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.5393 - val_accuracy: 0.9183\n",
            "Epoch 159/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9989\n",
            "Epoch 159: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.5333 - val_accuracy: 0.9176\n",
            "Epoch 160/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
            "Epoch 160: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.5175 - val_accuracy: 0.9229\n",
            "Epoch 161/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 161: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.5514 - val_accuracy: 0.9160\n",
            "Epoch 162/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 162: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.5317 - val_accuracy: 0.9176\n",
            "Epoch 163/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 163: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.5297 - val_accuracy: 0.9214\n",
            "Epoch 164/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
            "Epoch 164: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.5382 - val_accuracy: 0.9198\n",
            "Epoch 165/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
            "Epoch 165: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.5523 - val_accuracy: 0.9168\n",
            "Epoch 166/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 166: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5434 - val_accuracy: 0.9160\n",
            "Epoch 167/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9992\n",
            "Epoch 167: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.5612 - val_accuracy: 0.9145\n",
            "Epoch 168/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 168: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5568 - val_accuracy: 0.9206\n",
            "Epoch 169/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 169: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5513 - val_accuracy: 0.9198\n",
            "Epoch 170/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
            "Epoch 170: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.5559 - val_accuracy: 0.9160\n",
            "Epoch 171/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0090 - accuracy: 0.9972\n",
            "Epoch 171: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.6216 - val_accuracy: 0.9183\n",
            "Epoch 172/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
            "Epoch 172: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.5754 - val_accuracy: 0.9130\n",
            "Epoch 173/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0119 - accuracy: 0.9966\n",
            "Epoch 173: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.5777 - val_accuracy: 0.9176\n",
            "Epoch 174/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1020 - accuracy: 0.9705\n",
            "Epoch 174: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1085 - accuracy: 0.9688 - val_loss: 0.8931 - val_accuracy: 0.8580\n",
            "Epoch 175/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.9267\n",
            "Epoch 175: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2719 - accuracy: 0.9267 - val_loss: 0.7152 - val_accuracy: 0.8603\n",
            "Epoch 176/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1472 - accuracy: 0.9541\n",
            "Epoch 176: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1466 - accuracy: 0.9540 - val_loss: 0.5095 - val_accuracy: 0.8931\n",
            "Epoch 177/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0619 - accuracy: 0.9785\n",
            "Epoch 177: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0612 - accuracy: 0.9791 - val_loss: 0.5129 - val_accuracy: 0.8985\n",
            "Epoch 178/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0252 - accuracy: 0.9933\n",
            "Epoch 178: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.5128 - val_accuracy: 0.9099\n",
            "Epoch 179/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9946\n",
            "Epoch 179: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.5157 - val_accuracy: 0.9069\n",
            "Epoch 180/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0148 - accuracy: 0.9951\n",
            "Epoch 180: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.5136 - val_accuracy: 0.9092\n",
            "Epoch 181/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0079 - accuracy: 0.9981\n",
            "Epoch 181: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4897 - val_accuracy: 0.9130\n",
            "Epoch 182/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0047 - accuracy: 0.9992\n",
            "Epoch 182: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.4910 - val_accuracy: 0.9176\n",
            "Epoch 183/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 183: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.4857 - val_accuracy: 0.9153\n",
            "Epoch 184/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 184: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.4909 - val_accuracy: 0.9160\n",
            "Epoch 185/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9992\n",
            "Epoch 185: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4988 - val_accuracy: 0.9183\n",
            "Epoch 186/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
            "Epoch 186: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.4904 - val_accuracy: 0.9160\n",
            "Epoch 187/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
            "Epoch 187: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4954 - val_accuracy: 0.9183\n",
            "Epoch 188/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 188: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.5008 - val_accuracy: 0.9153\n",
            "Epoch 189/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 189: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.4956 - val_accuracy: 0.9206\n",
            "Epoch 190/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0021 - accuracy: 0.9996\n",
            "Epoch 190: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.5302 - val_accuracy: 0.9176\n",
            "Epoch 191/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0047 - accuracy: 0.9990\n",
            "Epoch 191: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.5156 - val_accuracy: 0.9160\n",
            "Epoch 192/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 192: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.5231 - val_accuracy: 0.9176\n",
            "Epoch 193/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 193: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.5157 - val_accuracy: 0.9214\n",
            "Epoch 194/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n",
            "Epoch 194: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.5227 - val_accuracy: 0.9168\n",
            "Epoch 195/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
            "Epoch 195: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5084 - val_accuracy: 0.9198\n",
            "Epoch 196/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 196: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.5166 - val_accuracy: 0.9153\n",
            "Epoch 197/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n",
            "Epoch 197: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.5636 - val_accuracy: 0.9191\n",
            "Epoch 198/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 198: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.5322 - val_accuracy: 0.9160\n",
            "Epoch 199/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9990\n",
            "Epoch 199: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.5235 - val_accuracy: 0.9191\n",
            "Epoch 200/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 200: val_accuracy did not improve from 0.92290\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.5269 - val_accuracy: 0.9176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Oq_ftckqbx0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the best model\n",
        "best_model = load_model('saved_models/best_fcn.hdf5')"
      ],
      "metadata": {
        "id": "Lu9CLzYEb07a"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the model has overfitted to the training data towards the end of the training. We have selected the model that performed better on the validation set, saved by the checkpoint. The similarity between validation and test score tells us that our training methodology is correct and that our validation set is a good estimator of testing performance."
      ],
      "metadata": {
        "id": "FSrTkxzCb2oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = best_model.evaluate(X_train, Y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = best_model.evaluate(X_val, Y_val, verbose=0)\n",
        "print(\"Validation Accuracy: \", score[1])\n",
        "\n",
        "score = best_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkHoKIXvb3SF",
        "outputId": "88b16d7f-77d8-4911-b05f-6fee52525ea9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9996727705001831\n",
            "Validation Accuracy:  0.9229007363319397\n",
            "Testing Accuracy:  0.9061068892478943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there has been overfitting so we could train another model adding dropout before the last layer to add more regularization."
      ],
      "metadata": {
        "id": "9lVga2nib6fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We add a dropout ratio of 0.25\n",
        "fcn_model = create_model(input_shape=X_train.shape[1:], dropout_ratio=0.5)\n",
        "fcn_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "fcn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zc5D39bb7LO",
        "outputId": "b15650a3-ec37-4f9c-bb67-bb6917333435"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 38, 171, 16)       144       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 19, 57, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 18, 54, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 9, 27, 32)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 24, 64)         16448     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 12, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 3, 9, 128)         65664     \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 128)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,674\n",
            "Trainable params: 87,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(filepath='saved_models/best_fcn_dropout.hdf5', monitor='val_accuracy',\n",
        "                               verbose=1, save_best_only=True)\n",
        "callbacks = [checkpointer]\n",
        "\n",
        "model = train_model(model=fcn_model,\n",
        "                    X_train=X_train,\n",
        "                    X_val=X_val,\n",
        "                    Y_train=Y_train,\n",
        "                    Y_val=Y_val,\n",
        "                    epochs=200,\n",
        "                    batch_size=256,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyWSZV5eb-fT",
        "outputId": "115174ea-b6fa-472e-dba2-27c957fbe12f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 2.3182 - accuracy: 0.2243\n",
            "Epoch 1: val_accuracy improved from -inf to 0.40000, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 4s 45ms/step - loss: 2.2846 - accuracy: 0.2322 - val_loss: 1.7687 - val_accuracy: 0.4000\n",
            "Epoch 2/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 1.6887 - accuracy: 0.3901\n",
            "Epoch 2: val_accuracy improved from 0.40000 to 0.49389, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 1.6785 - accuracy: 0.3923 - val_loss: 1.4690 - val_accuracy: 0.4939\n",
            "Epoch 3/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 1.4682 - accuracy: 0.4751\n",
            "Epoch 3: val_accuracy improved from 0.49389 to 0.55191, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 1.4571 - accuracy: 0.4771 - val_loss: 1.2749 - val_accuracy: 0.5519\n",
            "Epoch 4/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 1.3375 - accuracy: 0.5304\n",
            "Epoch 4: val_accuracy improved from 0.55191 to 0.57328, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 1.3293 - accuracy: 0.5301 - val_loss: 1.1957 - val_accuracy: 0.5733\n",
            "Epoch 5/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.2237 - accuracy: 0.5730\n",
            "Epoch 5: val_accuracy improved from 0.57328 to 0.60840, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 1.2237 - accuracy: 0.5730 - val_loss: 1.1300 - val_accuracy: 0.6084\n",
            "Epoch 6/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 1.1606 - accuracy: 0.5962\n",
            "Epoch 6: val_accuracy improved from 0.60840 to 0.63893, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 1.1645 - accuracy: 0.5964 - val_loss: 1.0361 - val_accuracy: 0.6389\n",
            "Epoch 7/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 1.0894 - accuracy: 0.6207\n",
            "Epoch 7: val_accuracy improved from 0.63893 to 0.67481, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 1.0894 - accuracy: 0.6207 - val_loss: 1.0037 - val_accuracy: 0.6748\n",
            "Epoch 8/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 1.0283 - accuracy: 0.6436\n",
            "Epoch 8: val_accuracy improved from 0.67481 to 0.68855, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 1.0275 - accuracy: 0.6445 - val_loss: 0.9232 - val_accuracy: 0.6885\n",
            "Epoch 9/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.9448 - accuracy: 0.6729\n",
            "Epoch 9: val_accuracy improved from 0.68855 to 0.70916, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.9463 - accuracy: 0.6741 - val_loss: 0.8645 - val_accuracy: 0.7092\n",
            "Epoch 10/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.9020 - accuracy: 0.6937\n",
            "Epoch 10: val_accuracy improved from 0.70916 to 0.73588, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.9020 - accuracy: 0.6937 - val_loss: 0.8131 - val_accuracy: 0.7359\n",
            "Epoch 11/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.8675 - accuracy: 0.7022\n",
            "Epoch 11: val_accuracy did not improve from 0.73588\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.8620 - accuracy: 0.7027 - val_loss: 0.7980 - val_accuracy: 0.7313\n",
            "Epoch 12/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.8152 - accuracy: 0.7200\n",
            "Epoch 12: val_accuracy improved from 0.73588 to 0.74275, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.8180 - accuracy: 0.7186 - val_loss: 0.7461 - val_accuracy: 0.7427\n",
            "Epoch 13/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.7317\n",
            "Epoch 13: val_accuracy improved from 0.74275 to 0.75115, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.7971 - accuracy: 0.7317 - val_loss: 0.7405 - val_accuracy: 0.7511\n",
            "Epoch 14/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.7567 - accuracy: 0.7470\n",
            "Epoch 14: val_accuracy improved from 0.75115 to 0.77176, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.7555 - accuracy: 0.7474 - val_loss: 0.6827 - val_accuracy: 0.7718\n",
            "Epoch 15/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.7531\n",
            "Epoch 15: val_accuracy did not improve from 0.77176\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.7238 - accuracy: 0.7531 - val_loss: 0.7108 - val_accuracy: 0.7511\n",
            "Epoch 16/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.7217 - accuracy: 0.7578\n",
            "Epoch 16: val_accuracy did not improve from 0.77176\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.7170 - accuracy: 0.7590 - val_loss: 0.6661 - val_accuracy: 0.7649\n",
            "Epoch 17/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.6655 - accuracy: 0.7737\n",
            "Epoch 17: val_accuracy improved from 0.77176 to 0.78168, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.6655 - accuracy: 0.7737 - val_loss: 0.6422 - val_accuracy: 0.7817\n",
            "Epoch 18/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.7768\n",
            "Epoch 18: val_accuracy improved from 0.78168 to 0.78626, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.6464 - accuracy: 0.7768 - val_loss: 0.6423 - val_accuracy: 0.7863\n",
            "Epoch 19/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.7907\n",
            "Epoch 19: val_accuracy improved from 0.78626 to 0.79618, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.6309 - accuracy: 0.7907 - val_loss: 0.6072 - val_accuracy: 0.7962\n",
            "Epoch 20/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.7989\n",
            "Epoch 20: val_accuracy improved from 0.79618 to 0.80076, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.5873 - accuracy: 0.7989 - val_loss: 0.5895 - val_accuracy: 0.8008\n",
            "Epoch 21/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.5769 - accuracy: 0.8017\n",
            "Epoch 21: val_accuracy improved from 0.80076 to 0.80229, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.5752 - accuracy: 0.8017 - val_loss: 0.5649 - val_accuracy: 0.8023\n",
            "Epoch 22/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.5483 - accuracy: 0.8162\n",
            "Epoch 22: val_accuracy improved from 0.80229 to 0.80840, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.5517 - accuracy: 0.8148 - val_loss: 0.5717 - val_accuracy: 0.8084\n",
            "Epoch 23/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.5661 - accuracy: 0.8074\n",
            "Epoch 23: val_accuracy did not improve from 0.80840\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.5643 - accuracy: 0.8086 - val_loss: 0.5572 - val_accuracy: 0.8031\n",
            "Epoch 24/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8205\n",
            "Epoch 24: val_accuracy improved from 0.80840 to 0.80916, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.5334 - accuracy: 0.8205 - val_loss: 0.5639 - val_accuracy: 0.8092\n",
            "Epoch 25/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.8295\n",
            "Epoch 25: val_accuracy improved from 0.80916 to 0.81527, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.5113 - accuracy: 0.8295 - val_loss: 0.5241 - val_accuracy: 0.8153\n",
            "Epoch 26/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.8279\n",
            "Epoch 26: val_accuracy improved from 0.81527 to 0.82901, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.4912 - accuracy: 0.8279 - val_loss: 0.4946 - val_accuracy: 0.8290\n",
            "Epoch 27/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4864 - accuracy: 0.8434\n",
            "Epoch 27: val_accuracy did not improve from 0.82901\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4805 - accuracy: 0.8444 - val_loss: 0.5562 - val_accuracy: 0.8214\n",
            "Epoch 28/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4884 - accuracy: 0.8350\n",
            "Epoch 28: val_accuracy did not improve from 0.82901\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4903 - accuracy: 0.8339 - val_loss: 0.5298 - val_accuracy: 0.8145\n",
            "Epoch 29/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4485 - accuracy: 0.8466\n",
            "Epoch 29: val_accuracy improved from 0.82901 to 0.83740, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.4580 - accuracy: 0.8424 - val_loss: 0.4711 - val_accuracy: 0.8374\n",
            "Epoch 30/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4573 - accuracy: 0.8434\n",
            "Epoch 30: val_accuracy did not improve from 0.83740\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4542 - accuracy: 0.8449 - val_loss: 0.4627 - val_accuracy: 0.8351\n",
            "Epoch 31/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4342 - accuracy: 0.8525\n",
            "Epoch 31: val_accuracy improved from 0.83740 to 0.84733, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.4393 - accuracy: 0.8505 - val_loss: 0.4517 - val_accuracy: 0.8473\n",
            "Epoch 32/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4278 - accuracy: 0.8528\n",
            "Epoch 32: val_accuracy did not improve from 0.84733\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4242 - accuracy: 0.8541 - val_loss: 0.4594 - val_accuracy: 0.8397\n",
            "Epoch 33/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.4025 - accuracy: 0.8615\n",
            "Epoch 33: val_accuracy improved from 0.84733 to 0.85420, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.4076 - accuracy: 0.8599 - val_loss: 0.4475 - val_accuracy: 0.8542\n",
            "Epoch 34/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8599\n",
            "Epoch 34: val_accuracy did not improve from 0.85420\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.4087 - accuracy: 0.8599 - val_loss: 0.4546 - val_accuracy: 0.8458\n",
            "Epoch 35/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8663\n",
            "Epoch 35: val_accuracy did not improve from 0.85420\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.3903 - accuracy: 0.8663 - val_loss: 0.4181 - val_accuracy: 0.8534\n",
            "Epoch 36/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.3921 - accuracy: 0.8629\n",
            "Epoch 36: val_accuracy improved from 0.85420 to 0.86183, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.3914 - accuracy: 0.8637 - val_loss: 0.4071 - val_accuracy: 0.8618\n",
            "Epoch 37/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.8743\n",
            "Epoch 37: val_accuracy did not improve from 0.86183\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.3635 - accuracy: 0.8743 - val_loss: 0.4211 - val_accuracy: 0.8550\n",
            "Epoch 38/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8753\n",
            "Epoch 38: val_accuracy did not improve from 0.86183\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.3677 - accuracy: 0.8753 - val_loss: 0.4232 - val_accuracy: 0.8550\n",
            "Epoch 39/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.8739\n",
            "Epoch 39: val_accuracy improved from 0.86183 to 0.86336, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.3585 - accuracy: 0.8739 - val_loss: 0.4228 - val_accuracy: 0.8634\n",
            "Epoch 40/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.3526 - accuracy: 0.8775\n",
            "Epoch 40: val_accuracy did not improve from 0.86336\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.3510 - accuracy: 0.8781 - val_loss: 0.4692 - val_accuracy: 0.8481\n",
            "Epoch 41/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.3629 - accuracy: 0.8774\n",
            "Epoch 41: val_accuracy did not improve from 0.86336\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.3613 - accuracy: 0.8784 - val_loss: 0.4308 - val_accuracy: 0.8565\n",
            "Epoch 42/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.3492 - accuracy: 0.8837\n",
            "Epoch 42: val_accuracy improved from 0.86336 to 0.86947, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.3504 - accuracy: 0.8830 - val_loss: 0.4149 - val_accuracy: 0.8695\n",
            "Epoch 43/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.3340 - accuracy: 0.8871\n",
            "Epoch 43: val_accuracy improved from 0.86947 to 0.87176, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.3369 - accuracy: 0.8868 - val_loss: 0.3930 - val_accuracy: 0.8718\n",
            "Epoch 44/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.3055 - accuracy: 0.8917\n",
            "Epoch 44: val_accuracy improved from 0.87176 to 0.87786, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.3077 - accuracy: 0.8920 - val_loss: 0.3867 - val_accuracy: 0.8779\n",
            "Epoch 45/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.3050 - accuracy: 0.8963\n",
            "Epoch 45: val_accuracy did not improve from 0.87786\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.3047 - accuracy: 0.8951 - val_loss: 0.4112 - val_accuracy: 0.8656\n",
            "Epoch 46/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.2944 - accuracy: 0.8979\n",
            "Epoch 46: val_accuracy did not improve from 0.87786\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2932 - accuracy: 0.8981 - val_loss: 0.4002 - val_accuracy: 0.8725\n",
            "Epoch 47/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2823 - accuracy: 0.9078\n",
            "Epoch 47: val_accuracy improved from 0.87786 to 0.87939, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.2833 - accuracy: 0.9062 - val_loss: 0.3819 - val_accuracy: 0.8794\n",
            "Epoch 48/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2785 - accuracy: 0.9039\n",
            "Epoch 48: val_accuracy did not improve from 0.87939\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.2790 - accuracy: 0.9035 - val_loss: 0.3810 - val_accuracy: 0.8771\n",
            "Epoch 49/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2859 - accuracy: 0.9018\n",
            "Epoch 49: val_accuracy did not improve from 0.87939\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.2881 - accuracy: 0.9018 - val_loss: 0.3792 - val_accuracy: 0.8779\n",
            "Epoch 50/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2699 - accuracy: 0.9075\n",
            "Epoch 50: val_accuracy improved from 0.87939 to 0.88931, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.2763 - accuracy: 0.9045 - val_loss: 0.3557 - val_accuracy: 0.8893\n",
            "Epoch 51/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2704 - accuracy: 0.9030\n",
            "Epoch 51: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2704 - accuracy: 0.9030 - val_loss: 0.3821 - val_accuracy: 0.8824\n",
            "Epoch 52/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.2908 - accuracy: 0.9030\n",
            "Epoch 52: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.2905 - accuracy: 0.9030 - val_loss: 0.4042 - val_accuracy: 0.8710\n",
            "Epoch 53/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.2871 - accuracy: 0.9025\n",
            "Epoch 53: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.2862 - accuracy: 0.9030 - val_loss: 0.3770 - val_accuracy: 0.8840\n",
            "Epoch 54/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.2578 - accuracy: 0.9098\n",
            "Epoch 54: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.2587 - accuracy: 0.9090 - val_loss: 0.3617 - val_accuracy: 0.8817\n",
            "Epoch 55/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9128\n",
            "Epoch 55: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.2525 - accuracy: 0.9128 - val_loss: 0.3678 - val_accuracy: 0.8870\n",
            "Epoch 56/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.9105\n",
            "Epoch 56: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2455 - accuracy: 0.9105 - val_loss: 0.3653 - val_accuracy: 0.8893\n",
            "Epoch 57/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2330 - accuracy: 0.9203\n",
            "Epoch 57: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.2328 - accuracy: 0.9200 - val_loss: 0.3713 - val_accuracy: 0.8802\n",
            "Epoch 58/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2377 - accuracy: 0.9167\n",
            "Epoch 58: val_accuracy did not improve from 0.88931\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2377 - accuracy: 0.9169 - val_loss: 0.3661 - val_accuracy: 0.8809\n",
            "Epoch 59/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2246 - accuracy: 0.9221\n",
            "Epoch 59: val_accuracy improved from 0.88931 to 0.89084, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.2277 - accuracy: 0.9200 - val_loss: 0.3412 - val_accuracy: 0.8908\n",
            "Epoch 60/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.9188\n",
            "Epoch 60: val_accuracy did not improve from 0.89084\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2332 - accuracy: 0.9188 - val_loss: 0.3884 - val_accuracy: 0.8725\n",
            "Epoch 61/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9141\n",
            "Epoch 61: val_accuracy did not improve from 0.89084\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.2396 - accuracy: 0.9141 - val_loss: 0.3576 - val_accuracy: 0.8885\n",
            "Epoch 62/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9192\n",
            "Epoch 62: val_accuracy did not improve from 0.89084\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2229 - accuracy: 0.9192 - val_loss: 0.3478 - val_accuracy: 0.8893\n",
            "Epoch 63/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2260 - accuracy: 0.9233\n",
            "Epoch 63: val_accuracy improved from 0.89084 to 0.90229, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.2251 - accuracy: 0.9242 - val_loss: 0.3571 - val_accuracy: 0.9023\n",
            "Epoch 64/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2209 - accuracy: 0.9228\n",
            "Epoch 64: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.2204 - accuracy: 0.9236 - val_loss: 0.3323 - val_accuracy: 0.8985\n",
            "Epoch 65/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9244\n",
            "Epoch 65: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2097 - accuracy: 0.9244 - val_loss: 0.3752 - val_accuracy: 0.8863\n",
            "Epoch 66/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9269\n",
            "Epoch 66: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2103 - accuracy: 0.9269 - val_loss: 0.4058 - val_accuracy: 0.8748\n",
            "Epoch 67/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1984 - accuracy: 0.9316\n",
            "Epoch 67: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1959 - accuracy: 0.9321 - val_loss: 0.3411 - val_accuracy: 0.8924\n",
            "Epoch 68/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1905 - accuracy: 0.9315\n",
            "Epoch 68: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1918 - accuracy: 0.9311 - val_loss: 0.3471 - val_accuracy: 0.8939\n",
            "Epoch 69/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1886 - accuracy: 0.9345\n",
            "Epoch 69: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1893 - accuracy: 0.9347 - val_loss: 0.3414 - val_accuracy: 0.8947\n",
            "Epoch 70/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1885 - accuracy: 0.9321\n",
            "Epoch 70: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1898 - accuracy: 0.9319 - val_loss: 0.3413 - val_accuracy: 0.9008\n",
            "Epoch 71/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.9305\n",
            "Epoch 71: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.1850 - accuracy: 0.9305 - val_loss: 0.3721 - val_accuracy: 0.8939\n",
            "Epoch 72/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1905 - accuracy: 0.9334\n",
            "Epoch 72: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.1900 - accuracy: 0.9339 - val_loss: 0.3501 - val_accuracy: 0.8893\n",
            "Epoch 73/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.2016 - accuracy: 0.9300\n",
            "Epoch 73: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.1997 - accuracy: 0.9292 - val_loss: 0.3709 - val_accuracy: 0.8878\n",
            "Epoch 74/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1882 - accuracy: 0.9346\n",
            "Epoch 74: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.1878 - accuracy: 0.9347 - val_loss: 0.3494 - val_accuracy: 0.8947\n",
            "Epoch 75/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9439\n",
            "Epoch 75: val_accuracy did not improve from 0.90229\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.1638 - accuracy: 0.9439 - val_loss: 0.3415 - val_accuracy: 0.9008\n",
            "Epoch 76/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9428\n",
            "Epoch 76: val_accuracy improved from 0.90229 to 0.90763, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.1564 - accuracy: 0.9427 - val_loss: 0.3491 - val_accuracy: 0.9076\n",
            "Epoch 77/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9437\n",
            "Epoch 77: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1612 - accuracy: 0.9437 - val_loss: 0.3363 - val_accuracy: 0.9053\n",
            "Epoch 78/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.9386\n",
            "Epoch 78: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1744 - accuracy: 0.9385 - val_loss: 0.3500 - val_accuracy: 0.8954\n",
            "Epoch 79/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9349\n",
            "Epoch 79: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1777 - accuracy: 0.9349 - val_loss: 0.3717 - val_accuracy: 0.8901\n",
            "Epoch 80/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1842 - accuracy: 0.9375\n",
            "Epoch 80: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1829 - accuracy: 0.9372 - val_loss: 0.3473 - val_accuracy: 0.9038\n",
            "Epoch 81/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.9396\n",
            "Epoch 81: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1741 - accuracy: 0.9396 - val_loss: 0.3407 - val_accuracy: 0.9069\n",
            "Epoch 82/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1698 - accuracy: 0.9404\n",
            "Epoch 82: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1702 - accuracy: 0.9401 - val_loss: 0.3596 - val_accuracy: 0.8992\n",
            "Epoch 83/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1636 - accuracy: 0.9421\n",
            "Epoch 83: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1644 - accuracy: 0.9421 - val_loss: 0.3698 - val_accuracy: 0.8924\n",
            "Epoch 84/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1475 - accuracy: 0.9469\n",
            "Epoch 84: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1474 - accuracy: 0.9473 - val_loss: 0.3780 - val_accuracy: 0.9008\n",
            "Epoch 85/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1476 - accuracy: 0.9482\n",
            "Epoch 85: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1494 - accuracy: 0.9470 - val_loss: 0.3522 - val_accuracy: 0.9046\n",
            "Epoch 86/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.9458\n",
            "Epoch 86: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1439 - accuracy: 0.9458 - val_loss: 0.3865 - val_accuracy: 0.8992\n",
            "Epoch 87/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1436 - accuracy: 0.9490\n",
            "Epoch 87: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1421 - accuracy: 0.9496 - val_loss: 0.3918 - val_accuracy: 0.8977\n",
            "Epoch 88/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1493 - accuracy: 0.9487\n",
            "Epoch 88: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1512 - accuracy: 0.9486 - val_loss: 0.3595 - val_accuracy: 0.9038\n",
            "Epoch 89/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1458 - accuracy: 0.9476\n",
            "Epoch 89: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1461 - accuracy: 0.9472 - val_loss: 0.3706 - val_accuracy: 0.8977\n",
            "Epoch 90/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1411 - accuracy: 0.9499\n",
            "Epoch 90: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1426 - accuracy: 0.9494 - val_loss: 0.3817 - val_accuracy: 0.8992\n",
            "Epoch 91/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1595 - accuracy: 0.9454\n",
            "Epoch 91: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.1595 - accuracy: 0.9454 - val_loss: 0.3721 - val_accuracy: 0.9000\n",
            "Epoch 92/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.9431\n",
            "Epoch 92: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.1604 - accuracy: 0.9429 - val_loss: 0.3572 - val_accuracy: 0.9000\n",
            "Epoch 93/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1439 - accuracy: 0.9489\n",
            "Epoch 93: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.1444 - accuracy: 0.9481 - val_loss: 0.3766 - val_accuracy: 0.9031\n",
            "Epoch 94/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1385 - accuracy: 0.9514\n",
            "Epoch 94: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.1379 - accuracy: 0.9516 - val_loss: 0.3753 - val_accuracy: 0.8992\n",
            "Epoch 95/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1552 - accuracy: 0.9469\n",
            "Epoch 95: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1570 - accuracy: 0.9460 - val_loss: 0.3662 - val_accuracy: 0.9061\n",
            "Epoch 96/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9534\n",
            "Epoch 96: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1353 - accuracy: 0.9534 - val_loss: 0.3844 - val_accuracy: 0.9015\n",
            "Epoch 97/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1165 - accuracy: 0.9576\n",
            "Epoch 97: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1203 - accuracy: 0.9570 - val_loss: 0.3793 - val_accuracy: 0.9069\n",
            "Epoch 98/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1177 - accuracy: 0.9593\n",
            "Epoch 98: val_accuracy did not improve from 0.90763\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1196 - accuracy: 0.9593 - val_loss: 0.3843 - val_accuracy: 0.9023\n",
            "Epoch 99/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1131 - accuracy: 0.9603\n",
            "Epoch 99: val_accuracy improved from 0.90763 to 0.90992, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.1118 - accuracy: 0.9607 - val_loss: 0.3781 - val_accuracy: 0.9099\n",
            "Epoch 100/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1106 - accuracy: 0.9597\n",
            "Epoch 100: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1139 - accuracy: 0.9593 - val_loss: 0.4080 - val_accuracy: 0.9031\n",
            "Epoch 101/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1471 - accuracy: 0.9485\n",
            "Epoch 101: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1479 - accuracy: 0.9486 - val_loss: 0.3964 - val_accuracy: 0.8962\n",
            "Epoch 102/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1280 - accuracy: 0.9540\n",
            "Epoch 102: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1259 - accuracy: 0.9547 - val_loss: 0.3893 - val_accuracy: 0.9038\n",
            "Epoch 103/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1212 - accuracy: 0.9592\n",
            "Epoch 103: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1266 - accuracy: 0.9575 - val_loss: 0.3988 - val_accuracy: 0.9076\n",
            "Epoch 104/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1228 - accuracy: 0.9570\n",
            "Epoch 104: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1233 - accuracy: 0.9566 - val_loss: 0.3673 - val_accuracy: 0.9084\n",
            "Epoch 105/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9599\n",
            "Epoch 105: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1087 - accuracy: 0.9599 - val_loss: 0.4071 - val_accuracy: 0.9069\n",
            "Epoch 106/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1095 - accuracy: 0.9615\n",
            "Epoch 106: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1108 - accuracy: 0.9607 - val_loss: 0.3970 - val_accuracy: 0.9038\n",
            "Epoch 107/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9565\n",
            "Epoch 107: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1214 - accuracy: 0.9565 - val_loss: 0.3770 - val_accuracy: 0.9069\n",
            "Epoch 108/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9601\n",
            "Epoch 108: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1178 - accuracy: 0.9601 - val_loss: 0.3883 - val_accuracy: 0.9053\n",
            "Epoch 109/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1223 - accuracy: 0.9552\n",
            "Epoch 109: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1231 - accuracy: 0.9553 - val_loss: 0.4215 - val_accuracy: 0.8908\n",
            "Epoch 110/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1196 - accuracy: 0.9553\n",
            "Epoch 110: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.1188 - accuracy: 0.9566 - val_loss: 0.3847 - val_accuracy: 0.9046\n",
            "Epoch 111/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1123 - accuracy: 0.9655\n",
            "Epoch 111: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.1129 - accuracy: 0.9653 - val_loss: 0.3747 - val_accuracy: 0.9076\n",
            "Epoch 112/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.9630\n",
            "Epoch 112: val_accuracy did not improve from 0.90992\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.1109 - accuracy: 0.9622 - val_loss: 0.3895 - val_accuracy: 0.9015\n",
            "Epoch 113/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9661\n",
            "Epoch 113: val_accuracy improved from 0.90992 to 0.91069, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0995 - accuracy: 0.9661 - val_loss: 0.3888 - val_accuracy: 0.9107\n",
            "Epoch 114/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1089 - accuracy: 0.9647\n",
            "Epoch 114: val_accuracy did not improve from 0.91069\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1096 - accuracy: 0.9647 - val_loss: 0.4126 - val_accuracy: 0.9046\n",
            "Epoch 115/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9604\n",
            "Epoch 115: val_accuracy did not improve from 0.91069\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1162 - accuracy: 0.9604 - val_loss: 0.4194 - val_accuracy: 0.9000\n",
            "Epoch 116/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9578\n",
            "Epoch 116: val_accuracy did not improve from 0.91069\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1205 - accuracy: 0.9578 - val_loss: 0.3699 - val_accuracy: 0.9069\n",
            "Epoch 117/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0991 - accuracy: 0.9670\n",
            "Epoch 117: val_accuracy did not improve from 0.91069\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1001 - accuracy: 0.9658 - val_loss: 0.3776 - val_accuracy: 0.9084\n",
            "Epoch 118/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1041 - accuracy: 0.9643\n",
            "Epoch 118: val_accuracy did not improve from 0.91069\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1042 - accuracy: 0.9647 - val_loss: 0.3999 - val_accuracy: 0.9069\n",
            "Epoch 119/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0989 - accuracy: 0.9648\n",
            "Epoch 119: val_accuracy improved from 0.91069 to 0.91679, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.1035 - accuracy: 0.9634 - val_loss: 0.3579 - val_accuracy: 0.9168\n",
            "Epoch 120/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9583\n",
            "Epoch 120: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1188 - accuracy: 0.9583 - val_loss: 0.3759 - val_accuracy: 0.9092\n",
            "Epoch 121/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9586\n",
            "Epoch 121: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1185 - accuracy: 0.9586 - val_loss: 0.3931 - val_accuracy: 0.9031\n",
            "Epoch 122/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9632\n",
            "Epoch 122: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1105 - accuracy: 0.9632 - val_loss: 0.4036 - val_accuracy: 0.9053\n",
            "Epoch 123/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9671\n",
            "Epoch 123: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0931 - accuracy: 0.9671 - val_loss: 0.4213 - val_accuracy: 0.9053\n",
            "Epoch 124/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.1009 - accuracy: 0.9650\n",
            "Epoch 124: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1011 - accuracy: 0.9661 - val_loss: 0.4182 - val_accuracy: 0.9046\n",
            "Epoch 125/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9594\n",
            "Epoch 125: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1145 - accuracy: 0.9594 - val_loss: 0.4172 - val_accuracy: 0.9145\n",
            "Epoch 126/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1042 - accuracy: 0.9631\n",
            "Epoch 126: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.1064 - accuracy: 0.9627 - val_loss: 0.3832 - val_accuracy: 0.9137\n",
            "Epoch 127/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0989 - accuracy: 0.9665\n",
            "Epoch 127: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0995 - accuracy: 0.9663 - val_loss: 0.3842 - val_accuracy: 0.9061\n",
            "Epoch 128/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9643\n",
            "Epoch 128: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1032 - accuracy: 0.9643 - val_loss: 0.3839 - val_accuracy: 0.9076\n",
            "Epoch 129/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9668\n",
            "Epoch 129: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.0957 - accuracy: 0.9668 - val_loss: 0.4000 - val_accuracy: 0.9099\n",
            "Epoch 130/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0821 - accuracy: 0.9735\n",
            "Epoch 130: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0843 - accuracy: 0.9732 - val_loss: 0.4122 - val_accuracy: 0.9015\n",
            "Epoch 131/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9648\n",
            "Epoch 131: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0990 - accuracy: 0.9648 - val_loss: 0.4493 - val_accuracy: 0.9015\n",
            "Epoch 132/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9661\n",
            "Epoch 132: val_accuracy did not improve from 0.91679\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.3972 - val_accuracy: 0.9122\n",
            "Epoch 133/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0947 - accuracy: 0.9638\n",
            "Epoch 133: val_accuracy improved from 0.91679 to 0.91832, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0939 - accuracy: 0.9643 - val_loss: 0.3738 - val_accuracy: 0.9183\n",
            "Epoch 134/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0955 - accuracy: 0.9677\n",
            "Epoch 134: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0947 - accuracy: 0.9679 - val_loss: 0.4272 - val_accuracy: 0.9015\n",
            "Epoch 135/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9705\n",
            "Epoch 135: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0875 - accuracy: 0.9705 - val_loss: 0.4070 - val_accuracy: 0.9137\n",
            "Epoch 136/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9668\n",
            "Epoch 136: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0900 - accuracy: 0.9668 - val_loss: 0.4093 - val_accuracy: 0.9076\n",
            "Epoch 137/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9733\n",
            "Epoch 137: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0767 - accuracy: 0.9733 - val_loss: 0.4226 - val_accuracy: 0.9130\n",
            "Epoch 138/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0745 - accuracy: 0.9746\n",
            "Epoch 138: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0745 - accuracy: 0.9745 - val_loss: 0.3773 - val_accuracy: 0.9145\n",
            "Epoch 139/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9733\n",
            "Epoch 139: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0756 - accuracy: 0.9733 - val_loss: 0.4050 - val_accuracy: 0.9061\n",
            "Epoch 140/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.9720\n",
            "Epoch 140: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0762 - accuracy: 0.9720 - val_loss: 0.4276 - val_accuracy: 0.9130\n",
            "Epoch 141/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9688\n",
            "Epoch 141: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0829 - accuracy: 0.9688 - val_loss: 0.3997 - val_accuracy: 0.9160\n",
            "Epoch 142/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0763 - accuracy: 0.9734\n",
            "Epoch 142: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0775 - accuracy: 0.9732 - val_loss: 0.4285 - val_accuracy: 0.9092\n",
            "Epoch 143/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0797 - accuracy: 0.9705\n",
            "Epoch 143: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0785 - accuracy: 0.9704 - val_loss: 0.4357 - val_accuracy: 0.9092\n",
            "Epoch 144/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0877 - accuracy: 0.9700\n",
            "Epoch 144: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0874 - accuracy: 0.9704 - val_loss: 0.4216 - val_accuracy: 0.9053\n",
            "Epoch 145/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0898 - accuracy: 0.9710\n",
            "Epoch 145: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0884 - accuracy: 0.9715 - val_loss: 0.4116 - val_accuracy: 0.9145\n",
            "Epoch 146/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0721 - accuracy: 0.9743\n",
            "Epoch 146: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0758 - accuracy: 0.9727 - val_loss: 0.4264 - val_accuracy: 0.9183\n",
            "Epoch 147/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0682 - accuracy: 0.9759\n",
            "Epoch 147: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0685 - accuracy: 0.9759 - val_loss: 0.4255 - val_accuracy: 0.9168\n",
            "Epoch 148/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0697 - accuracy: 0.9750\n",
            "Epoch 148: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.4379 - val_accuracy: 0.9046\n",
            "Epoch 149/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9714\n",
            "Epoch 149: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0860 - accuracy: 0.9714 - val_loss: 0.4337 - val_accuracy: 0.9160\n",
            "Epoch 150/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9691\n",
            "Epoch 150: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0878 - accuracy: 0.9691 - val_loss: 0.4466 - val_accuracy: 0.9092\n",
            "Epoch 151/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0925 - accuracy: 0.9696\n",
            "Epoch 151: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0960 - accuracy: 0.9694 - val_loss: 0.4650 - val_accuracy: 0.9122\n",
            "Epoch 152/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9692\n",
            "Epoch 152: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0927 - accuracy: 0.9692 - val_loss: 0.4399 - val_accuracy: 0.9092\n",
            "Epoch 153/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9723\n",
            "Epoch 153: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0829 - accuracy: 0.9723 - val_loss: 0.4099 - val_accuracy: 0.9061\n",
            "Epoch 154/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9730\n",
            "Epoch 154: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0803 - accuracy: 0.9730 - val_loss: 0.4467 - val_accuracy: 0.9122\n",
            "Epoch 155/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0840 - accuracy: 0.9700\n",
            "Epoch 155: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0834 - accuracy: 0.9705 - val_loss: 0.4370 - val_accuracy: 0.9076\n",
            "Epoch 156/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0708 - accuracy: 0.9766\n",
            "Epoch 156: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.4043 - val_accuracy: 0.9107\n",
            "Epoch 157/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0772 - accuracy: 0.9728\n",
            "Epoch 157: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0785 - accuracy: 0.9725 - val_loss: 0.4688 - val_accuracy: 0.9069\n",
            "Epoch 158/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0685 - accuracy: 0.9769\n",
            "Epoch 158: val_accuracy did not improve from 0.91832\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0700 - accuracy: 0.9766 - val_loss: 0.4271 - val_accuracy: 0.9137\n",
            "Epoch 159/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0582 - accuracy: 0.9782\n",
            "Epoch 159: val_accuracy improved from 0.91832 to 0.91985, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0616 - accuracy: 0.9774 - val_loss: 0.3998 - val_accuracy: 0.9198\n",
            "Epoch 160/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0808 - accuracy: 0.9738\n",
            "Epoch 160: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0808 - accuracy: 0.9737 - val_loss: 0.4577 - val_accuracy: 0.9115\n",
            "Epoch 161/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0743 - accuracy: 0.9757\n",
            "Epoch 161: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0745 - accuracy: 0.9755 - val_loss: 0.4291 - val_accuracy: 0.9092\n",
            "Epoch 162/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0895 - accuracy: 0.9709\n",
            "Epoch 162: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0862 - accuracy: 0.9719 - val_loss: 0.4334 - val_accuracy: 0.9023\n",
            "Epoch 163/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0871 - accuracy: 0.9665\n",
            "Epoch 163: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0872 - accuracy: 0.9665 - val_loss: 0.4232 - val_accuracy: 0.9107\n",
            "Epoch 164/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0749 - accuracy: 0.9738\n",
            "Epoch 164: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0776 - accuracy: 0.9732 - val_loss: 0.4157 - val_accuracy: 0.9122\n",
            "Epoch 165/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0960 - accuracy: 0.9680\n",
            "Epoch 165: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0968 - accuracy: 0.9679 - val_loss: 0.5047 - val_accuracy: 0.8977\n",
            "Epoch 166/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.1086 - accuracy: 0.9643\n",
            "Epoch 166: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.1085 - accuracy: 0.9643 - val_loss: 0.4268 - val_accuracy: 0.9115\n",
            "Epoch 167/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0811 - accuracy: 0.9732\n",
            "Epoch 167: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0794 - accuracy: 0.9735 - val_loss: 0.4662 - val_accuracy: 0.9107\n",
            "Epoch 168/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9743\n",
            "Epoch 168: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0780 - accuracy: 0.9743 - val_loss: 0.4324 - val_accuracy: 0.9115\n",
            "Epoch 169/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9774\n",
            "Epoch 169: val_accuracy did not improve from 0.91985\n",
            "24/24 [==============================] - 1s 33ms/step - loss: 0.0634 - accuracy: 0.9774 - val_loss: 0.4993 - val_accuracy: 0.9122\n",
            "Epoch 170/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9786\n",
            "Epoch 170: val_accuracy improved from 0.91985 to 0.92061, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 0.0608 - accuracy: 0.9786 - val_loss: 0.4724 - val_accuracy: 0.9206\n",
            "Epoch 171/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0654 - accuracy: 0.9789\n",
            "Epoch 171: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 0.4475 - val_accuracy: 0.9130\n",
            "Epoch 172/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0554 - accuracy: 0.9822\n",
            "Epoch 172: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.4377 - val_accuracy: 0.9084\n",
            "Epoch 173/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0713 - accuracy: 0.9754\n",
            "Epoch 173: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0706 - accuracy: 0.9756 - val_loss: 0.4593 - val_accuracy: 0.9145\n",
            "Epoch 174/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0847 - accuracy: 0.9716\n",
            "Epoch 174: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0852 - accuracy: 0.9717 - val_loss: 0.4917 - val_accuracy: 0.9107\n",
            "Epoch 175/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0718 - accuracy: 0.9753\n",
            "Epoch 175: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0738 - accuracy: 0.9741 - val_loss: 0.4978 - val_accuracy: 0.9099\n",
            "Epoch 176/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0703 - accuracy: 0.9747\n",
            "Epoch 176: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.5499 - val_accuracy: 0.9099\n",
            "Epoch 177/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0619 - accuracy: 0.9782\n",
            "Epoch 177: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0625 - accuracy: 0.9782 - val_loss: 0.4257 - val_accuracy: 0.9183\n",
            "Epoch 178/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0655 - accuracy: 0.9766\n",
            "Epoch 178: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.0634 - accuracy: 0.9773 - val_loss: 0.4969 - val_accuracy: 0.9183\n",
            "Epoch 179/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0653 - accuracy: 0.9793\n",
            "Epoch 179: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0662 - accuracy: 0.9786 - val_loss: 0.5055 - val_accuracy: 0.9107\n",
            "Epoch 180/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0592 - accuracy: 0.9789\n",
            "Epoch 180: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.4434 - val_accuracy: 0.9168\n",
            "Epoch 181/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0581 - accuracy: 0.9803\n",
            "Epoch 181: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0591 - accuracy: 0.9802 - val_loss: 0.4613 - val_accuracy: 0.9183\n",
            "Epoch 182/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0549 - accuracy: 0.9828\n",
            "Epoch 182: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0559 - accuracy: 0.9827 - val_loss: 0.5207 - val_accuracy: 0.9023\n",
            "Epoch 183/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0544 - accuracy: 0.9827\n",
            "Epoch 183: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0531 - accuracy: 0.9833 - val_loss: 0.4702 - val_accuracy: 0.9183\n",
            "Epoch 184/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0611 - accuracy: 0.9789\n",
            "Epoch 184: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0603 - accuracy: 0.9791 - val_loss: 0.4817 - val_accuracy: 0.9160\n",
            "Epoch 185/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0747 - accuracy: 0.9740\n",
            "Epoch 185: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0751 - accuracy: 0.9737 - val_loss: 0.4433 - val_accuracy: 0.9153\n",
            "Epoch 186/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0705 - accuracy: 0.9761\n",
            "Epoch 186: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 35ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 0.5196 - val_accuracy: 0.9000\n",
            "Epoch 187/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0737 - accuracy: 0.9759\n",
            "Epoch 187: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 31ms/step - loss: 0.0739 - accuracy: 0.9756 - val_loss: 0.4479 - val_accuracy: 0.9145\n",
            "Epoch 188/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0710 - accuracy: 0.9760\n",
            "Epoch 188: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.0715 - accuracy: 0.9763 - val_loss: 0.5422 - val_accuracy: 0.9145\n",
            "Epoch 189/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0746 - accuracy: 0.9757\n",
            "Epoch 189: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 0.0751 - accuracy: 0.9756 - val_loss: 0.4693 - val_accuracy: 0.9076\n",
            "Epoch 190/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9727\n",
            "Epoch 190: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0728 - accuracy: 0.9727 - val_loss: 0.4777 - val_accuracy: 0.9046\n",
            "Epoch 191/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0778 - accuracy: 0.9754\n",
            "Epoch 191: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0762 - accuracy: 0.9759 - val_loss: 0.5304 - val_accuracy: 0.9122\n",
            "Epoch 192/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0695 - accuracy: 0.9769\n",
            "Epoch 192: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0690 - accuracy: 0.9769 - val_loss: 0.5217 - val_accuracy: 0.9092\n",
            "Epoch 193/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 0.9781\n",
            "Epoch 193: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0653 - accuracy: 0.9781 - val_loss: 0.5377 - val_accuracy: 0.9069\n",
            "Epoch 194/200\n",
            "22/24 [==========================>...] - ETA: 0s - loss: 0.0790 - accuracy: 0.9748\n",
            "Epoch 194: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0793 - accuracy: 0.9751 - val_loss: 0.5251 - val_accuracy: 0.9061\n",
            "Epoch 195/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.9728\n",
            "Epoch 195: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0812 - accuracy: 0.9728 - val_loss: 0.5401 - val_accuracy: 0.9038\n",
            "Epoch 196/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9746\n",
            "Epoch 196: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0731 - accuracy: 0.9746 - val_loss: 0.5179 - val_accuracy: 0.9092\n",
            "Epoch 197/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0847 - accuracy: 0.9713\n",
            "Epoch 197: val_accuracy did not improve from 0.92061\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.0841 - accuracy: 0.9715 - val_loss: 0.4322 - val_accuracy: 0.9168\n",
            "Epoch 198/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0673 - accuracy: 0.9772\n",
            "Epoch 198: val_accuracy improved from 0.92061 to 0.92137, saving model to saved_models/best_fcn_dropout.hdf5\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0663 - accuracy: 0.9779 - val_loss: 0.4566 - val_accuracy: 0.9214\n",
            "Epoch 199/200\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9859\n",
            "Epoch 199: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.0478 - accuracy: 0.9859 - val_loss: 0.4770 - val_accuracy: 0.9145\n",
            "Epoch 200/200\n",
            "23/24 [===========================>..] - ETA: 0s - loss: 0.0513 - accuracy: 0.9820\n",
            "Epoch 200: val_accuracy did not improve from 0.92137\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.5196 - val_accuracy: 0.9145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('saved_models/best_fcn_dropout.hdf5')"
      ],
      "metadata": {
        "id": "OMIq8XqacC2y"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = best_model.evaluate(X_train, Y_train, verbose=0)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = best_model.evaluate(X_val, Y_val, verbose=0)\n",
        "print(\"Validation Accuracy: \", score[1])\n",
        "\n",
        "score = best_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzK-IVffcEzK",
        "outputId": "e78ef47b-6a10-4bd4-eebe-535ced7b8e0d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.9991819262504578\n",
            "Validation Accuracy:  0.9213740229606628\n",
            "Testing Accuracy:  0.9083969593048096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a confusion matrix\n",
        "from sklearn import metrics\n",
        "Y_pred = best_model.predict(X_test)\n",
        "matrix = metrics.confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_3h6spqcI2r",
        "outputId": "ace781b0-db27-4142-b3a7-fa34fc0b29d0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix code (from https://github.com/triagemd/keras-eval/blob/master/keras_eval/visualizer.py)\n",
        "def plot_confusion_matrix(cm, concepts, normalize=False, show_text=True, fontsize=18, figsize=(16, 12),\n",
        "                          cmap=plt.cm.coolwarm_r, save_path=None, show_labels=True):\n",
        "    '''\n",
        "    Plot confusion matrix provided in 'cm'\n",
        "    Args:\n",
        "        cm: Confusion Matrix, square sized numpy array\n",
        "        concepts: Name of the categories to show\n",
        "        normalize: If True, normalize values between 0 and ones. Not valid if negative values.\n",
        "        show_text: If True, display cell values as text. Otherwise only display cell colors.\n",
        "        fontsize: Size of text\n",
        "        figsize: Size of figure\n",
        "        cmap: Color choice\n",
        "        save_path: If `save_path` specified, save confusion matrix in that location\n",
        "    Returns: Nothing. Plots confusion matrix\n",
        "    '''\n",
        "\n",
        "    if cm.ndim != 2 or cm.shape[0] != cm.shape[1]:\n",
        "        raise ValueError('Invalid confusion matrix shape, it should be square and ndim=2')\n",
        "\n",
        "    if cm.shape[0] != len(concepts) or cm.shape[1] != len(concepts):\n",
        "        raise ValueError('Number of concepts (%i) and dimensions of confusion matrix do not coincide (%i, %i)' %\n",
        "                         (len(concepts), cm.shape[0], cm.shape[1]))\n",
        "\n",
        "    plt.rcParams.update({'font.size': fontsize})\n",
        "\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    if normalize:\n",
        "        cm = cm_normalized\n",
        "\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm, vmin=np.min(cm), vmax=np.max(cm), alpha=0.8, cmap=cmap)\n",
        "\n",
        "    fig.colorbar(cax)\n",
        "    ax.xaxis.tick_bottom()\n",
        "    plt.ylabel('True label', fontweight='bold')\n",
        "    plt.xlabel('Predicted label', fontweight='bold')\n",
        "\n",
        "    if show_labels:\n",
        "        n_labels = len(concepts)\n",
        "        ax.set_xticklabels(concepts)\n",
        "        ax.set_yticklabels(concepts)\n",
        "        plt.xticks(np.arange(0, n_labels, 1.0), rotation='vertical')\n",
        "        plt.yticks(np.arange(0, n_labels, 1.0))\n",
        "    else:\n",
        "        plt.axis('off')\n",
        "\n",
        "    if show_text:\n",
        "        # http://stackoverflow.com/questions/21712047/matplotlib-imshow-matshow-display-values-on-plot\n",
        "        min_val, max_val = 0, len(concepts)\n",
        "        ind_array = np.arange(min_val, max_val, 1.0)\n",
        "        x, y = np.meshgrid(ind_array, ind_array)\n",
        "        for i, (x_val, y_val) in enumerate(zip(x.flatten(), y.flatten())):\n",
        "            c = cm[int(x_val), int(y_val)]\n",
        "            ax.text(y_val, x_val, c, va='center', ha='center')\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path)    "
      ],
      "metadata": {
        "id": "ukJc92SocMD6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To observe better the performance of the model and the mistakes made between different classes we plot the confusion matrix.\n",
        "\n",
        "In our case accuracy is a good metric because the dataset is mostly balanced but we observed a few classes with less samples (1car_horn, gun_shot and siren), so it will be good to observe the performance on these classes.\n",
        "\n",
        "We can observe that a lot of mistakes are happening between class children_playing and class street_music so maybe it will be worth it to spend a little bit more time doing analysis and finding what could be the reasons."
      ],
      "metadata": {
        "id": "Epk7iMhscQ6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dictionary = {3: 'dog_bark', 2: 'children_playing', 1: 'car_horn', 0: 'air_conditioner', 9: 'street_music', 6: 'gun_shot', 8: 'siren', 5: 'engine_idling', 7: 'jackhammer', 4: 'drilling'}\n",
        "classes = [class_dictionary[key] for key in sorted(class_dictionary.keys())]"
      ],
      "metadata": {
        "id": "EzFdtByCcRot"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(matrix, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oOQarkkPcVE7",
        "outputId": "6307ff30-0781-446b-dd8f-14584c666819"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-c573271be435>:42: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(concepts)\n",
            "<ipython-input-51-c573271be435>:43: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(concepts)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1200 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions"
      ],
      "metadata": {
        "id": "ehmqp1RTcWvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe a bump of 1-2% in the test set accuracy when introducing dropout as regularization. This shows that it has been a successful addition to our model.\n",
        "\n",
        "There are many things that we can try to improve the model's performance such as:\n",
        "\n",
        "  * Hyperparameter tuning:\n",
        "\n",
        "      * Tuning the parameters of feature extraction\n",
        "      * Tuning the network parameters (number of layers, pooling layers, number and filter shape...)\n",
        "      * Tuning the network hyperparameters (Learning rate, optimizer)\n",
        "  * Feature extraction:\n",
        "      * Use STFT: The raw spectogram could provide more information to the CNN to learn correlation between frequency and time than the MFCCs.\n",
        "      * Use Mel-Spectogram: The mel-spectogram could provide more information to the CNN to learn correlation between frequency and time than the MFCCs."
      ],
      "metadata": {
        "id": "PNXuhyokXV_K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eqPwQ5ylcXgP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}